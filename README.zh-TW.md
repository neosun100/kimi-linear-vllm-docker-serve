# Kimi-Linear-48B-A3B?? Docker ??????? vLLM ???

???? **? Docker ??**?????? vLLM??? Kimi-Linear-48B-A3B-Instruct?AWQ-4bit?? OpenAI ?? API????????????????????????????? 128K ????? 1M?

## ??
- ?? `vllm/vllm-openai:nightly`
- ????? `fla-core`
- ??????? TP/?????/?????/?????
- Makefile ?? build/run/push ????

## ????
```bash
docker build -t neosun100/kimi-linear-vllm:latest .
```

## ????
```bash
export HF_HOME="$HOME/.cache/huggingface"
export VLLM_DOWNLOAD_DIR="$HOME/vllm_downloads"
mkdir -p "$HF_HOME" "$VLLM_DOWNLOAD_DIR"

docker run --gpus all -d --name kimi48b-awq --restart unless-stopped \
  --ipc=host -p 8002:8000 \
  -v "$HF_HOME":/root/.cache/huggingface \
  -v "$VLLM_DOWNLOAD_DIR":/data/vllm_downloads \
  neosun100/kimi-linear-vllm:latest
```

## ?????????
```bash
curl http://localhost:8002/v1/models

curl http://localhost:8002/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "cyankiwi/Kimi-Linear-48B-A3B-Instruct-AWQ-4bit",
    "messages": [{"role":"user","content":"???"}],
    "max_tokens": 64
  }'
```

## ????????? -e ???
- `MODEL`????`cyankiwi/Kimi-Linear-48B-A3B-Instruct-AWQ-4bit`?
- `PORT`????`8000`?
- `TP`????`4`?
- `MAX_LEN`????`131072`??????? `1048576`?
- `GPU_MEM_UTIL`????`0.5`?
- `MAX_NUM_SEQS`????`64`?
- `DOWNLOAD_DIR`????`/data/vllm_downloads`?

???
```bash
docker run --gpus all -d --name kimi48b-awq -p 8002:8000 \
  -v "$HF_HOME":/root/.cache/huggingface \
  -v "$VLLM_DOWNLOAD_DIR":/data/vllm_downloads \
  -e MAX_LEN=1048576 -e GPU_MEM_UTIL=0.45 -e MAX_NUM_SEQS=32 \
  neosun100/kimi-linear-vllm:latest
```

## ????
### Docker Hub
```bash
# docker login
docker push neosun100/kimi-linear-vllm:latest
```

### GitHub Container Registry????
```bash
# gh auth login?? write:packages?
docker tag neosun100/kimi-linear-vllm:latest ghcr.io/neosun100/kimi-linear-vllm:latest
docker push ghcr.io/neosun100/kimi-linear-vllm:latest
```

## Makefile ??
```bash
make build
make run HOST_PORT=8002
make logs
make stop
make push
make ghcr-push
```

## ??
- ????? `fla-core` ??? Kimi-Linear ? tokenizer/??
- ???? 128K ????????? 1M
- ????? `--quantization`?? vLLM ???? AWQ
